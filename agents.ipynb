{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import ZeroShotAgent, Tool, AgentExecutor\n",
    "from langchain import OpenAI, SerpAPIWrapper, LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = SerpAPIWrapper(serpapi_api_key = '3dfe8719d1b2d956f807032cdd219bb70b1169c0')\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\"Answer the following questions as best you can, but speaking as a pirate might speak. You have access to the following tools:\"\"\"\n",
    "suffix = \"\"\"Begin! Remember to speak as a pirate when giving your final answer. Use lots of \"Args\"\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "prompt = ZeroShotAgent.create_prompt(\n",
    "    tools, \n",
    "    prefix=prefix, \n",
    "    suffix=suffix, \n",
    "    input_variables=[\"input\", \"agent_scratchpad\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can, but speaking as a pirate might speak. You have access to the following tools:\n",
      "\n",
      "Search: useful for when you need to answer questions about current events\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Search]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin! Remember to speak as a pirate when giving your final answer. Use lots of \"Args\"\n",
      "\n",
      "Question: {input}\n",
      "{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "print(prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for OpenAI\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass  `openai_api_key` as a named parameter. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m llm_chain \u001b[39m=\u001b[39m LLMChain(llm\u001b[39m=\u001b[39mOpenAI(temperature\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m), prompt\u001b[39m=\u001b[39mprompt)\n",
      "File \u001b[0;32m~/Desktop/sentimate/langchain-experiments-main/lan-env/lib/python3.8/site-packages/pydantic/main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for OpenAI\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass  `openai_api_key` as a named parameter. (type=value_error)"
     ]
    }
   ],
   "source": [
    "llm_chain = LLMChain(llm=OpenAI(temperature=0,), prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'output_keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m llm\u001b[39m=\u001b[39mHuggingFaceHub(repo_id\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgoogle/flan-t5-xl\u001b[39m\u001b[39m\"\u001b[39m, model_kwargs\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mtemperature\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m1e-10\u001b[39m})\n\u001b[1;32m     11\u001b[0m question \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mWhen was Google founded?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 13\u001b[0m \u001b[39mprint\u001b[39m(LLMChain\u001b[39m.\u001b[39;49mrun(question))\n",
      "File \u001b[0;32m~/Desktop/sentimate/langchain-experiments-main/lan-env/lib/python3.8/site-packages/langchain/chains/base.py:204\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    203\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Run the chain as text in, text out or multiple variables, text out.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 204\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput_keys) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    205\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    206\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`run` not supported when there is not exactly \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    207\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mone output key. Got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    208\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     \u001b[39mif\u001b[39;00m args \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kwargs:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'output_keys'"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"hf_ElQpYuGSbBMfDdzBycSrAOhQkeusuDUvZFi\"\n",
    "\n",
    "from langchain import PromptTemplate, HuggingFaceHub, LLMChain\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "llm=HuggingFaceHub(repo_id=\"google/flan-t5-xl\", model_kwargs={\"temperature\":1e-10})\n",
    "\n",
    "question = \"When was Google founded?\"\n",
    "\n",
    "print(LLMChain.run(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in ./lan-env/lib/python3.8/site-packages (0.13.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./lan-env/lib/python3.8/site-packages (from huggingface_hub) (6.0)\n",
      "Requirement already satisfied: filelock in ./lan-env/lib/python3.8/site-packages (from huggingface_hub) (3.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in ./lan-env/lib/python3.8/site-packages (from huggingface_hub) (23.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./lan-env/lib/python3.8/site-packages (from huggingface_hub) (4.65.0)\n",
      "Requirement already satisfied: requests in ./lan-env/lib/python3.8/site-packages (from huggingface_hub) (2.28.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./lan-env/lib/python3.8/site-packages (from huggingface_hub) (4.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./lan-env/lib/python3.8/site-packages (from requests->huggingface_hub) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./lan-env/lib/python3.8/site-packages (from requests->huggingface_hub) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./lan-env/lib/python3.8/site-packages (from requests->huggingface_hub) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./lan-env/lib/python3.8/site-packages (from requests->huggingface_hub) (1.26.15)\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lan-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
